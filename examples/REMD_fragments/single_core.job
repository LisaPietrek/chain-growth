#!/bin/bash -l
# Standard output and error:
#SBATCH -o ./name.out.%j
#SBATCH -e ./name.err.%j
# Initial working directory:
#SBATCH -D ./
#
#SBATCH -J job_name
# Queue:
#SBATCH --partition=s.phys       # NEEDED; otherwise the job blocks a whole node
#SBATCH --mem=1000             # Memory is necessary if using only part of a node
#
# Number of nodes and MPI tasks per node:
#SBATCH --ntasks-per-node=1
#SBATCH  --cpus-per-task=1
#SBATCH --mail-type=none
#SBATCH --mail-user=%u@rzg.mpg.de
#
# wall clock limit:
#SBATCH --time=01:00:00

#module load purge
module load intel/19.1.3
module load impi/2019.9
module load gromacs/2019.6

# submit script for running e.g. grompp on cluster to automatize whole REMD setup
# can also be run in bash if you prefer not to submit this

script=$1
s=$2 # first fragment
e=$3 # last fragment
sys=$4
for i in $(seq $s $e) ; do
 cd $i
 bash $script $sys
 cd .. ;
done

